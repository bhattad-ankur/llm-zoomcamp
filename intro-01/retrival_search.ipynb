{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c55ebfb-55a1-493d-a6ce-d791f2cb9a4d",
   "metadata": {},
   "source": [
    "# Retrival & Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2db88017-6a8d-4283-892e-9ba70b37adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/refs/heads/main/minsearch.py\n",
    "# !wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4301d27-087f-406c-b18f-d9514f577eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import minsearch\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm \n",
    "\n",
    "# os.chdir(\"intro-01/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d85fd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_search_engine(document_location) : \n",
    "\n",
    "    with open(document_location , \"rt\") as f_in :\n",
    "        docs_raw =  json.load(f_in)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for course_dict in docs_raw : \n",
    "        for docs in course_dict['documents'] : \n",
    "            docs['course'] = course_dict['course']\n",
    "            documents.append(docs)\n",
    "\n",
    "    index = minsearch.Index(\n",
    "    text_fields= ['text' , 'section' , 'question'],\n",
    "    keyword_fields= ['course']\n",
    "    )\n",
    "\n",
    "    index.fit(documents)\n",
    "\n",
    "    return index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8890e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query , search_engine) : \n",
    "\n",
    "    boost = { 'question' : 3.0  , \"section\": 0.3 }\n",
    "\n",
    "    results = search_engine.search(\n",
    "        query= query, \n",
    "        boost_dict= boost, \n",
    "        num_results= 3,\n",
    "        filter_dict= {'course' : 'data-engineering-zoomcamp'}\n",
    "    )\n",
    "\n",
    "    context = \"\"\n",
    "    for doc in results:\n",
    "        context += f\"section: {doc['section']} \\nquestion: {doc['question']}\\ntext: {doc['text']}\"\n",
    "    \n",
    "    return context\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "580697d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_client_name = \"course-questions\"\n",
    "\n",
    "def train_elastic_search(document_location , es_client_name ,  elastic_search_loc = 'http://localhost:9200') : \n",
    "    \n",
    "    es_client =  Elasticsearch(elastic_search_loc)\n",
    "    # es_client.info()\n",
    "\n",
    "    index_settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"section\": {\"type\": \"text\"},\n",
    "                \"question\": {\"type\": \"text\"},\n",
    "                \"course\": {\"type\": \"keyword\"} \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    es_client.indices.create(index = es_client_name , body = index_settings )\n",
    "\n",
    "    with open(document_location , \"rt\") as f_in :\n",
    "        docs_raw =  json.load(f_in)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for course_dict in docs_raw : \n",
    "        for docs in course_dict['documents'] : \n",
    "            docs['course'] = course_dict['course']\n",
    "            documents.append(docs)\n",
    "\n",
    "    for doc in tqdm(documents) : \n",
    "        es_client.index( index = es_client_name , document = doc)\n",
    "    \n",
    "def elastic_search(es_client_name , query , elastic_search_loc = 'http://localhost:9200') :\n",
    "\n",
    "    es_client =  Elasticsearch(elastic_search_loc)\n",
    "\n",
    "    search_query = { \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response  = es_client.search(index = es_client_name , body = search_query)\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response['hits']['hits'] : \n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c1d430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query , search_results) : \n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a teaching assitant. Answer the questions based on the CONTEXT.\n",
    "    Use only facts when asnwering the QUESTION from CONTEXT. \n",
    "    If the CONTEXT does not have a answer return none.\n",
    "\n",
    "    QUESTION: {query}\n",
    "    CONTEXT: {search_results} \"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59ab6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt  , api_key) : \n",
    "    \n",
    "    import google.generativeai as genai\n",
    "    genai.configure(api_key = api_key)\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "    chat = model.start_chat(history=[])\n",
    "    response = chat.send_message(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5587f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['GOOGLE_API_KEY']\n",
    "search_engine = train_search_engine(document_location = \"documents.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87cb694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"how do I run kafka\"\n",
    "\n",
    "answer = llm(prompt= build_prompt(query= query , search_results = elastic_search(es_client_name=\"course-questions\" , query=query) ) , api_key = api_key)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5e2e9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
